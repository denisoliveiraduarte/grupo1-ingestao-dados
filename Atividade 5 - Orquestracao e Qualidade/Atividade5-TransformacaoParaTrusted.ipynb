{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%idle_timeout 2880\n",
    "%glue_version 3.0\n",
    "%worker_type G.1X\n",
    "%number_of_workers 5\n",
    "%additional_python_modules awswrangler, great_expectations, https://github.com/julioasotodv/spark-df-profiling/archive/master.zip, pyyaml, datacompy\n",
    "\n",
    "\n",
    "import sys\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "  \n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace, when, isnull, trim, avg, count, sum\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "import awswrangler as wr\n",
    "import spark_df_profiling\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "import great_expectations as ge\n",
    "from great_expectations.data_context import BaseDataContext\n",
    "from great_expectations.data_context.types.base import DataContextConfig, S3StoreBackendDefaults\n",
    "from great_expectations.checkpoint import SimpleCheckpoint\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "import boto3\n",
    "import yaml\n",
    "import re\n",
    "import sys\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from great_expectations.data_context.types.resource_identifiers import ValidationResultIdentifier, \\\n",
    "    ExpectationSuiteIdentifier, BatchIdentifier\n",
    "s3 = boto3.resource(\"s3\")\n",
    "bucket = s3.Bucket('atividade5-raw')\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.get_object(Bucket='atividade5-raw',\n",
    "                                Key=\"great_expectations/great_expectations.yaml\")\n",
    "configfile = yaml.safe_load(response[\"Body\"])\n",
    "folder = \"great_expectations/\"\n",
    "bucketNameRaw = \"atividade5-raw/\"\n",
    "bucketNameTrusted = \"atividade5-trusted/\"\n",
    "\n",
    "pastaBancos = \"bancos/\"\n",
    "pastaEmpregados = \"empregados/\"\n",
    "pastaReclamacoes = \"reclamacoes/\"\n",
    "df_bancos = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", True).option(\"charset\", \"latin1\").csv('s3://'+bucketNameRaw+pastaBancos)\n",
    "df_empregados = spark.read.option(\"delimiter\", \"|\").option(\"header\", True).csv('s3://'+bucketNameRaw+pastaEmpregados)\n",
    "df_reclamacoes = spark.read.option(\"delimiter\", \";\").option(\"header\", True).csv('s3://'+bucketNameRaw+pastaReclamacoes)\n",
    "profile_bancos = spark_df_profiling.ProfileReport(df_bancos, title=\"pyspark_bancos\", minimal=True)\n",
    "bucket.put_object(Key=folder + 'pyspark_bancos.html', Body=profile_bancos.rendered_html(), ContentType='text/html')\n",
    "config = DataContextConfig(config_version=configfile['config_version'], datasources=configfile['datasources'],\n",
    "                           expectations_store_name=configfile['expectations_store_name'],\n",
    "                           validations_store_name=configfile['validations_store_name'],\n",
    "                           evaluation_parameter_store_name=configfile['evaluation_parameter_store_name'],\n",
    "                           plugins_directory='/great_expectations/plugins',\n",
    "                           stores=configfile['stores'],\n",
    "                           data_docs_sites=configfile['data_docs_sites'],\n",
    "                           store_backend_defaults=S3StoreBackendDefaults(\n",
    "                               default_bucket_name=configfile['data_docs_sites']['s3_site']['store_backend']['bucket']))\n",
    "profile_empregados = spark_df_profiling.ProfileReport(df_empregados, title=\"pyspark_empregados\", minimal=True)\n",
    "bucket.put_object(Key=folder + 'pyspark_empregados.html', Body=profile_empregados.rendered_html(), ContentType='text/html')\n",
    "config = DataContextConfig(config_version=configfile['config_version'], datasources=configfile['datasources'],\n",
    "                           expectations_store_name=configfile['expectations_store_name'],\n",
    "                           validations_store_name=configfile['validations_store_name'],\n",
    "                           evaluation_parameter_store_name=configfile['evaluation_parameter_store_name'],\n",
    "                           plugins_directory='/great_expectations/plugins',\n",
    "                           stores=configfile['stores'],\n",
    "                           data_docs_sites=configfile['data_docs_sites'],\n",
    "                           store_backend_defaults=S3StoreBackendDefaults(\n",
    "                               default_bucket_name=configfile['data_docs_sites']['s3_site']['store_backend']['bucket']))\n",
    "profile_reclamacoes = spark_df_profiling.ProfileReport(df_reclamacoes, title=\"pyspark_reclamacoes\", minimal=True)\n",
    "bucket.put_object(Key=folder + 'pyspark_reclamacoes.html', Body=profile_reclamacoes.rendered_html(), ContentType='text/html')\n",
    "config = DataContextConfig(config_version=configfile['config_version'], datasources=configfile['datasources'],\n",
    "                           expectations_store_name=configfile['expectations_store_name'],\n",
    "                           validations_store_name=configfile['validations_store_name'],\n",
    "                           evaluation_parameter_store_name=configfile['evaluation_parameter_store_name'],\n",
    "                           plugins_directory='/great_expectations/plugins',\n",
    "                           stores=configfile['stores'],\n",
    "                           data_docs_sites=configfile['data_docs_sites'],\n",
    "                           store_backend_defaults=S3StoreBackendDefaults(\n",
    "                               default_bucket_name=configfile['data_docs_sites']['s3_site']['store_backend']['bucket']))\n",
    "column_to_rename_old = ['Segmento','CNPJ','Nome']\n",
    "column_to_rename_new = ['segmento','cnpj','nome']\n",
    "for i in range(len(column_to_rename_old)):\n",
    "    df_bancos = df_bancos.withColumnRenamed(column_to_rename_old[i], column_to_rename_new[i])\n",
    "df_bancos = df_bancos.withColumn(\"nome\", regexp_replace(\"nome\", \" - PRUDENCIAL\", \"\"))\n",
    "column_to_rename_old = ['employer_name', 'reviews_count', 'culture_count', 'salaries_count', 'benefits_count', 'employer-website', 'employer-headquarters', 'employer-founded', 'employer-industry', 'employer-revenue', 'url', 'Geral', 'Cultura e valores', 'Diversidade e inclusao', 'Qualidade de vida', 'Alta lideranca', 'Remuneracao e beneficios', 'Oportunidades de carreira', 'Recomendam para outras pessoas(%)', 'Perspectiva positiva da empresa(%)', 'CNPJ', 'Nome', 'match_percent']\n",
    "column_to_rename_new = ['employer_name', 'reviews_count', 'culture_count', 'salaries_count', 'benefits_count', 'employer_website', 'employer_headquarters', 'employer_founded', 'employer_industry', 'employer_revenue', 'url', 'geral', 'cultura_e_valores', 'diversidade_e_inclusao', 'qualidade_de_vida', 'alta_lideranca', 'remuneracao_e_beneficios', 'oportunidades_de_carreira', 'recomendam_para_outras_pessoas_perc', 'perspectiva_positiva_da_empresa_perc', 'cnpj_emp', 'nome_emp', 'match_percent']\n",
    "\n",
    "for i in range(len(column_to_rename_old)):\n",
    "    df_empregados = df_empregados.withColumnRenamed(column_to_rename_old[i], column_to_rename_new[i])\n",
    "\n",
    "columns = [\"nome_emp\", col(\"geral\").cast(\"float\").alias(\"geral\"),col(\"remuneracao_e_beneficios\").cast(\"float\").alias(\"remuneracao_e_beneficios\")]\n",
    "\n",
    "df_empregados = df_empregados.select(columns)\n",
    "column_to_rename_old = ['Ano', 'Trimestre', 'Categoria', 'Tipo', 'CNPJ IF', 'Instituicao financeira', 'indice', 'Quantidade de reclamacoes reguladas procedentes', 'Quantidade de reclamacoes reguladas - outras', 'Quantidade de reclamacoes nno reguladas', 'Quantidade total de reclamacoes', 'Quantidade total de clientes - CCS e SCR', 'Quantidade de clientes - CCS', 'Quantidade de clientes - SCR',',,']\n",
    "column_to_rename_new = ['ano', 'trimestre', 'categoria', 'tipo', 'cnpj_if', 'instituicao_financeira', 'indice', 'quantidade_de_reclamacoes_reguladas_procedentes', 'quantidade_de_reclamacoes_reguladas_outras', 'quantidade_de_reclamacoes_nao_reguladas', 'quantidade_total_de_reclamacoes', 'quantidade_total_de_clientes_ccs_e_scr', 'quantidade_de_clientes_ccs', 'quantidade_de_clientes_scr', ',,']\n",
    "for i in range(len(column_to_rename_old)):\n",
    "    df_reclamacoes = df_reclamacoes.withColumnRenamed(column_to_rename_old[i], column_to_rename_new[i])\n",
    "df_reclamacoes = df_reclamacoes.withColumn(\"trimestre\", regexp_replace(\"trimestre\", \"o\", \"\"))\n",
    "df_reclamacoes = df_reclamacoes.withColumn(\"instituicao_financeira\", regexp_replace(\"instituicao_financeira\", \"conglomerado\", \"\"))\n",
    "df_reclamacoes = df_reclamacoes.withColumn(\"instituicao_financeira\", regexp_replace(\"instituicao_financeira\",\"[()]\",\"\"))\n",
    "df_reclamacoes = df_reclamacoes.withColumn(\"instituicao_financeira\",trim(col(\"instituicao_financeira\")))\n",
    "df_reclamacoes = df_reclamacoes.withColumn(\"indice\", regexp_replace(\"indice\",\",\",\".\"))\n",
    "columns = [col(\"ano\").cast(\"int\").alias(\"ano\"), \"trimestre\",col(\"instituicao_financeira\").alias(\"nome_rec\"),col(\"indice\").cast(\"float\").alias(\"indice\"),\\\n",
    "           col(\"quantidade_total_de_reclamacoes\").cast(\"int\").alias(\"qtd_reclamacoes\"),col(\"quantidade_total_de_clientes_ccs_e_scr\").cast(\"int\").alias(\"qtd_clientes\")]\n",
    "\n",
    "df_reclamacoes = df_reclamacoes.select(columns)\n",
    "df_bancos.write.mode(\"overwrite\").parquet('s3://'+bucketNameTrusted+pastaBancos)\n",
    "df_empregados.write.mode(\"overwrite\").parquet('s3://'+bucketNameTrusted+pastaEmpregados)\n",
    "df_reclamacoes.write.mode(\"overwrite\").parquet('s3://'+bucketNameTrusted+pastaReclamacoes)\n",
    "job.commit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
